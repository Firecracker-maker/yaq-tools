{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30614676-fe09-427e-bf68-8e0041f0b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7c3df477-9e49-4663-acf3-7be0af1357d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b39e0c96-594d-4ed3-b942-ad2489885c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "34f466f3-57a5-4ebf-8c4a-a9fc32dad0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\n",
    "    os.environ.get(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ddfa403f-90e3-4045-8682-7151d89303ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_models = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b678a730-0992-4f86-ab8e-783712851b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for model in existing_models:\n",
    "    df = pd.DataFrame({\"id\": model.id,\n",
    "                       \"created\": pd.Timestamp(datetime.fromtimestamp(model.created, \n",
    "                                                                      tz=pytz.UTC)),\n",
    "                       \"object\": model.object,\n",
    "                       \"owned_by\": model.owned_by\n",
    "                      }, index=[0, 1, 2, 3])\n",
    "    dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "607df909-1f2a-4ba3-b556-7f8ae0bfa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "84ec11c5-076c-49fb-825b-d13e0375127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values(by=[\"created\"], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "54be0690-9a4a-4055-870c-6c5fc72c36dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>object</th>\n",
       "      <th>owned_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>2023-02-28 18:56:42+00:00</td>\n",
       "      <td>model</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>2023-02-28 18:56:42+00:00</td>\n",
       "      <td>model</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>2023-02-28 18:56:42+00:00</td>\n",
       "      <td>model</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>2023-02-28 18:56:42+00:00</td>\n",
       "      <td>model</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                   created object owned_by\n",
       "2  gpt-3.5-turbo 2023-02-28 18:56:42+00:00  model   openai\n",
       "1  gpt-3.5-turbo 2023-02-28 18:56:42+00:00  model   openai\n",
       "3  gpt-3.5-turbo 2023-02-28 18:56:42+00:00  model   openai\n",
       "0  gpt-3.5-turbo 2023-02-28 18:56:42+00:00  model   openai"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models[df_models[\"owned_by\"]==\"openai\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19713fba-605b-4a9a-84e3-40898442f566",
   "metadata": {},
   "source": [
    "In OpenAI models, temperature is a parameter that controls the randomness of the model's output. It affects how deterministic or creative the responses are.\n",
    "\n",
    "How It Works:\n",
    "- Temperature adjusts the probability distribution of the modelâ€™s predictions.\n",
    "- Lower temperatures make the model favor the highest-probability outputs, resulting in more predictable and structured responses.\n",
    "- Higher temperatures make the model more exploratory by sampling less probable outputs, leading to more diverse and creative results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8f7d5d44-10b9-4c5d-81e7-c62a526b5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "# we want to test data and we need to be precise so taking a small number.\n",
    "TEMPERATURE = 0.3\n",
    "MAX_TOKENS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "878d4a39-92f3-4938-833a-40c8363ac1fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     41\u001b[0m system_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am Data Software engineer using python. I want to verify with real data if my function do what\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms intended\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 42\u001b[0m my_function \u001b[38;5;241m=\u001b[39m my_function\n\u001b[1;32m     43\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompare the holiday list output from my \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_function\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with all the Good Friday Holidays since 1908. Make sure all dates are available, if not return the missing ones.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m answer \u001b[38;5;241m=\u001b[39m request_gpt(system_message, prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_function' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_gpt_message(system_message, prompt):\n",
    "    \"\"\"\n",
    "    Generate a ChatGpt message with the system message and the prompt\n",
    "    Parameters\n",
    "    ----------\n",
    "    system_message\n",
    "    prompt\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    return message\n",
    "\n",
    "\n",
    "def request_gpt(system_message, prompt):\n",
    "    \"\"\"\n",
    "    Request GPT to answer your prompt with the system message.\n",
    "    Parameters\n",
    "    ----------\n",
    "    system_message: \n",
    "    prompt: \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=generate_gpt_message(system_message, prompt),\n",
    "        temperature=temperature,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "system_message = \"I am Data Software engineer using python. I want to verify with real data if my function do what's intended\"\n",
    "my_function = my_function\n",
    "prompt = f\"Compare the holiday list output from my {my_function} with all the Good Friday Holidays since 1908. Make sure all dates are available, if not return the missing ones.\"\n",
    "\n",
    "answer = request_gpt(system_message, prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e0192-d9e1-4689-afe7-d3ac79fcbd42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-deltalake-env",
   "language": "python",
   "name": "conda-env-.conda-deltalake-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
